{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Twitter ?\n",
    "\n",
    "\n",
    "    \n",
    "1. Copy the file `dot.twitter_config` to your home directory with the following command. Note that the `dot` portion of the name will be removed. It was only present in the course repo so that the file would not be invisible.\n",
    "    ```console\n",
    "    cp dot.twitter_config $HOME/.twitter_config\n",
    "    ```  \n",
    "2. Create a Twitter account if you don't have one. You may have to add a cellphone to your twitter account, to create an App. Write a couple test tweets if you are new to twitter. Then, navigate to [apps.twitter.com](https://apps.twitter.com/) and sign in.\n",
    "2. Select `Create New App`. Enter a name, description, and website (you can use http://thisismetis.com) if you want. Click the agreement and select `Create your Twitter application`.\n",
    "3. Navigate to the `Keys and Access Tokens` tab. Select `Create my access token`. Copy the following to the file `.twitter_config` that is in your home directory:\n",
    "    * Consumer Key\n",
    "    * Consumer Secret\n",
    "    * Access Token\n",
    "    * Access Token Secret\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest API vs Streaming API: \n",
    "\n",
    "\n",
    "REST:  \n",
    "    - Query user accounts using OAuth\n",
    "    - Allows you to access 'historical' tweets\n",
    "\n",
    "STREAM:  \n",
    "    - Essentially long-running request (left Open) using OAuth\n",
    "    - Access realtime stream of data\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rest API\n",
    "\n",
    "On your laptop, install the two required libraries.\n",
    "\n",
    "```console\n",
    "conda install -y -c conda-forge requests-oauthlib \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:25.222810Z",
     "start_time": "2017-05-11T11:26:24.309659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    "\n",
    "import pandas as pd\n",
    "import os, ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the OAuth configuration file you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "config_path = os.path.expanduser(\"~/.twitter_config\")\n",
    "with open(config_path,'r') as f:\n",
    "    config = ast.literal_eval(f.read())\n",
    "\n",
    "\n",
    "oauth = OAuth1(config[\"consumer_key\"],\n",
    "               config[\"consumer_secret\"],\n",
    "               config[\"access_token\"],\n",
    "               config[\"access_token_secret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this authorization token, get a list of your recent tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:25.516422Z",
     "start_time": "2017-05-11T11:26:25.236375Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "id\n",
      "id_str\n",
      "text\n",
      "truncated\n",
      "entities\n",
      "source\n",
      "in_reply_to_status_id\n",
      "in_reply_to_status_id_str\n",
      "in_reply_to_user_id\n",
      "in_reply_to_user_id_str\n",
      "in_reply_to_screen_name\n",
      "user\n",
      "geo\n",
      "coordinates\n",
      "place\n",
      "contributors\n",
      "is_quote_status\n",
      "retweet_count\n",
      "favorite_count\n",
      "favorited\n",
      "retweeted\n",
      "lang\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://api.twitter.com/1.1/statuses/user_timeline.json\",\n",
    "                        auth=oauth)\n",
    "\n",
    "tweets = response.json()\n",
    "\n",
    "for key in tweets[0].keys():\n",
    "    print(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:25.522229Z",
     "start_time": "2017-05-11T11:26:25.518163Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prb_data Thaddeus and I are curious where your profile pic is taken at:D\n",
      "Fuck hackers. im making a new account. Fuck.\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets[:5]:\n",
    "    print(tweet['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for tweets on Monica Rogati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:25.866436Z",
     "start_time": "2017-05-11T11:26:25.523821Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completed_in': 0.031,\n",
      " 'count': 2,\n",
      " 'max_id': 866834597408985088,\n",
      " 'max_id_str': '866834597408985088',\n",
      " 'next_results': '?max_id=866834405473501183&q=data%20science&count=2&include_entities=1',\n",
      " 'query': 'data+science',\n",
      " 'refresh_url': '?since_id=866834597408985088&q=data%20science&include_entities=1',\n",
      " 'since_id': 0,\n",
      " 'since_id_str': '0'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"q\": \"data science\", \"count\":2}\n",
    "response = requests.get(\"https://api.twitter.com/1.1/search/tweets.json\",\n",
    "                        params = parameters,\n",
    "                        auth=oauth)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(response.json()['search_metadata'])\n",
    "#pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:25.877734Z",
     "start_time": "2017-05-11T11:26:25.868412Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAGE 1\n",
      "866834597408985088 RT @Intellipaat: What is #DataScience? Read more to know what is Data Science all about!! https://t.co/zF0sAvDBUs\n"
     ]
    }
   ],
   "source": [
    "tweets = response.json()['statuses']\n",
    "\n",
    "print('PAGE 1')\n",
    "for tweet in tweets[:1]:\n",
    "    print(tweet['id'], tweet['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the next page of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:25.902494Z",
     "start_time": "2017-05-11T11:26:25.879754Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completed_in': 0.02,\n",
       " 'count': 2,\n",
       " 'max_id': 866834405473501183,\n",
       " 'max_id_str': '866834405473501183',\n",
       " 'next_results': '?max_id=866834031832440832&q=data%20science&count=2&include_entities=1',\n",
       " 'query': 'data+science',\n",
       " 'refresh_url': '?since_id=866834405473501183&q=data%20science&include_entities=1',\n",
       " 'since_id': 0,\n",
       " 'since_id_str': '0'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['search_metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:26.241750Z",
     "start_time": "2017-05-11T11:26:25.904315Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAGE 2\n",
      "CuÃ¡nto pagarÃ­as por un periÃ³dico con las noticias de maÃ±ana? AÃºn no lo hacemos pero estamos cerca, DATA SCIENCE elâ€¦ https://t.co/VXRd3rtX4S\n",
      "RT @passionatechica: Why did .@therriaultphd - Former Director of Data Science for the DNC (2014-2016) delete a tweet mocking #SethRich ???â€¦\n"
     ]
    }
   ],
   "source": [
    "search_url = \"https://api.twitter.com/1.1/search/tweets.json\"\n",
    "next_page_url = search_url + response.json()['search_metadata']['next_results']\n",
    "next_page_url\n",
    "response = requests.get(next_page_url, auth=oauth)\n",
    "\n",
    "print('PAGE 2')\n",
    "for tweet in response.json()['statuses'][:5]:\n",
    "    print(tweet['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming API: Tweepy\n",
    "\n",
    "We can also use the streaming API. Install tweepy on your laptop with the following command:\n",
    "```console\n",
    "conda install -y -c conda-forge tweepy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:26.262680Z",
     "start_time": "2017-05-11T11:26:26.243409Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(config[\"consumer_key\"],\n",
    "                           config[\"consumer_secret\"])\n",
    "\n",
    "auth.set_access_token(config[\"access_token\"],\n",
    "                      config[\"access_token_secret\"])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:26.652073Z",
     "start_time": "2017-05-11T11:26:26.270458Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @DataJunkie: After watching @RichardSocherâ€™s lecture on word2vec, I finally see that word2vec is not just a neural net version of LSA. Câ€¦\n",
      "RT @DataJunkie: After watching @RichardSocherâ€™s lecture on word2vec, I finally see that word2vec is not just a neural net version of LSA. Câ€¦\n",
      "After watching @RichardSocherâ€™s lecture on word2vec, I finally see that word2vec is not just a neural net version of LSA. Catching up.\n",
      "RT @ledell: Awesome to see @juliasilge from @StackOverflow using @h2oai's #Word2Vec on SO comments!  \n",
      "\n",
      "w2v #rstats demo here: https://t.co/â€¦\n",
      "Awesome to see @juliasilge from @StackOverflow using @h2oai's #Word2Vec on SO comments!  \n",
      "\n",
      "w2v #rstats demo here:â€¦ https://t.co/TvdDiFTNK9\n",
      "RT @juliasilge: I trained a word2vec model on @StackOverflow comments. ðŸ˜® #rstats (attn: @ledell) https://t.co/8h5L1Bwf4H\n",
      "RT @juliasilge: I trained a word2vec model on @StackOverflow comments. ðŸ˜® #rstats (attn: @ledell) https://t.co/8h5L1Bwf4H\n",
      "RT @juliasilge: I trained a word2vec model on @StackOverflow comments. ðŸ˜® #rstats (attn: @ledell) https://t.co/8h5L1Bwf4H\n",
      "I trained a word2vec model on @StackOverflow comments. ðŸ˜® #rstats (attn: @ledell) https://t.co/8h5L1Bwf4H\n",
      "Funny visualization of word2vec https://t.co/xDjQdsCw3A\n"
     ]
    }
   ],
   "source": [
    "max_tweets=10\n",
    "\n",
    "#Tweepy Cursor handles pagination .. \n",
    "\n",
    "for tweet in tweepy.Cursor(api.search, q=\"word2vec\").items(max_tweets):\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:26.956064Z",
     "start_time": "2017-05-11T11:26:26.653876Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search, q=\"word2vec\").items(10):\n",
    "    results.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:26.963599Z",
     "start_time": "2017-05-11T11:26:26.958256Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @DataJunkie: After watching @RichardSocherâ€™s lecture on word2vec, I finally see that word2vec is not just a neural net version of LSA. Câ€¦'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tweets into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:26.974220Z",
     "start_time": "2017-05-11T11:26:26.965515Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def structure_results(results):\n",
    "    id_list = [tweet.id for tweet in results]\n",
    "    data = pd.DataFrame(id_list, columns=['id'])\n",
    "    \n",
    "    data[\"text\"]     = [tweet.text.encode('utf-8') for tweet in results]\n",
    "    data[\"datetime\"] = [tweet.created_at for tweet in results]\n",
    "    data[\"Location\"] = [tweet.place for tweet in results]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:26.995279Z",
     "start_time": "2017-05-11T11:26:26.976018Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>866830626699132928</td>\n",
       "      <td>b'RT @DataJunkie: After watching @RichardSoche...</td>\n",
       "      <td>2017-05-23 01:38:20</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>866830057204965378</td>\n",
       "      <td>b'RT @DataJunkie: After watching @RichardSoche...</td>\n",
       "      <td>2017-05-23 01:36:05</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>866829417753923584</td>\n",
       "      <td>b'After watching @RichardSocher\\xe2\\x80\\x99s l...</td>\n",
       "      <td>2017-05-23 01:33:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>866824373239296000</td>\n",
       "      <td>b\"RT @ledell: Awesome to see @juliasilge from ...</td>\n",
       "      <td>2017-05-23 01:13:30</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>866824368806010880</td>\n",
       "      <td>b\"Awesome to see @juliasilge from @StackOverfl...</td>\n",
       "      <td>2017-05-23 01:13:28</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>866823990597349376</td>\n",
       "      <td>b'RT @juliasilge: I trained a word2vec model o...</td>\n",
       "      <td>2017-05-23 01:11:58</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>866823787580334081</td>\n",
       "      <td>b'RT @juliasilge: I trained a word2vec model o...</td>\n",
       "      <td>2017-05-23 01:11:10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>866821852143865856</td>\n",
       "      <td>b'RT @juliasilge: I trained a word2vec model o...</td>\n",
       "      <td>2017-05-23 01:03:28</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>866821848872308737</td>\n",
       "      <td>b'I trained a word2vec model on @StackOverflow...</td>\n",
       "      <td>2017-05-23 01:03:28</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>866735437796311040</td>\n",
       "      <td>b'Funny visualization of word2vec https://t.co...</td>\n",
       "      <td>2017-05-22 19:20:06</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  866830626699132928  b'RT @DataJunkie: After watching @RichardSoche...   \n",
       "1  866830057204965378  b'RT @DataJunkie: After watching @RichardSoche...   \n",
       "2  866829417753923584  b'After watching @RichardSocher\\xe2\\x80\\x99s l...   \n",
       "3  866824373239296000  b\"RT @ledell: Awesome to see @juliasilge from ...   \n",
       "4  866824368806010880  b\"Awesome to see @juliasilge from @StackOverfl...   \n",
       "5  866823990597349376  b'RT @juliasilge: I trained a word2vec model o...   \n",
       "6  866823787580334081  b'RT @juliasilge: I trained a word2vec model o...   \n",
       "7  866821852143865856  b'RT @juliasilge: I trained a word2vec model o...   \n",
       "8  866821848872308737  b'I trained a word2vec model on @StackOverflow...   \n",
       "9  866735437796311040  b'Funny visualization of word2vec https://t.co...   \n",
       "\n",
       "             datetime Location  \n",
       "0 2017-05-23 01:38:20     None  \n",
       "1 2017-05-23 01:36:05     None  \n",
       "2 2017-05-23 01:33:32     None  \n",
       "3 2017-05-23 01:13:30     None  \n",
       "4 2017-05-23 01:13:28     None  \n",
       "5 2017-05-23 01:11:58     None  \n",
       "6 2017-05-23 01:11:10     None  \n",
       "7 2017-05-23 01:03:28     None  \n",
       "8 2017-05-23 01:03:28     None  \n",
       "9 2017-05-22 19:20:06     None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = structure_results(results)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tweets into MongoDB\n",
    "\n",
    "Make sure the SSH tunnel to mongoDB that you started earlier this morning is still running. If not, start it with:\n",
    "\n",
    "```console\n",
    "ssh -NL 12345:localhost:27017 myaws\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:27.060382Z",
     "start_time": "2017-05-11T11:26:26.997081Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "client = MongoClient(port=12345)\n",
    "db = client.legislation\n",
    "tweets = db.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:27.301654Z",
     "start_time": "2017-05-11T11:26:27.061967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in results:\n",
    "    data = {}\n",
    "    data['tweet'] = tweet.text.encode('utf-8') \n",
    "    data['datetime'] = tweet.created_at\n",
    "    tweets.insert_one(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-11T11:26:27.327187Z",
     "start_time": "2017-05-11T11:26:27.305791Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('59239ab0c79810573df709a4'),\n",
       " 'datetime': datetime.datetime(2017, 5, 23, 1, 38, 20),\n",
       " 'tweet': b'RT @DataJunkie: After watching @RichardSocher\\xe2\\x80\\x99s lecture on word2vec, I finally see that word2vec is not just a neural net version of LSA. C\\xe2\\x80\\xa6'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
