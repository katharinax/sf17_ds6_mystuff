{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import cv2, numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.misc import imread, imsave\n",
    "import re\n",
    "import idx2numpy as idx\n",
    "from copy import copy\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# keras\n",
    "np.random.seed(13)\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Reshape, Activation, SimpleRNN, GRU, LSTM, Convolution1D, \\\n",
    "                         MaxPooling1D, Merge, Dropout, Input\n",
    "from IPython.display import SVG\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Activation, Lambda, Layer # keras.layers.core \n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.datasets import mnist\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootpath = \"../EgyptianHieroglyphDataset/MyTrainTest\"\n",
    "original_dim = (75, 50) # without convolutional layers, use 75 * 50\n",
    "batch_size = 32 * 2 # this has to be the same as the param value in the analysis code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol_num</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>Z7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol_num symbol\n",
       "170         170     Z7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_rootpath = os.path.join(rootpath, \"train\")\n",
    "symbol_df = [x for x in os.listdir(tr_rootpath) if re.search(r\"UNKNOWN|^\\.\", x) == None]\n",
    "symbol_df = pd.DataFrame(sorted(symbol_df))\n",
    "symbol_df.reset_index(inplace = True)\n",
    "symbol_df.columns = [\"symbol_num\", \"symbol\"]\n",
    "symbol_df.tail(1)\n",
    "# TODO pickle symbol_df; load if when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"/home/ubuntu/egypt/data/after_augmentation_but_wrong_shape/x_train.pkl\")\n",
    "y_train = np.load(\"/home/ubuntu/egypt/data/after_augmentation_but_wrong_shape/y_train.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the records\n",
    "Need to get rid of these three images so that total training data is divisible by batch size  \n",
    "These correspond to: gen3_410397_O50.png, gen3_410385_O50.png, gen3_410365_O50.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113\n",
       "1    113\n",
       "2    113\n",
       "Name: temp, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.argmax(y_train[41814:41817, :], 1), name = \"temp\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing code to see if things work\n",
    "# temp = np.array([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7])\n",
    "# temp = np.reshape(temp, (7, 1, 2, 2))\n",
    "# np.vstack([temp[:3], temp[5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55875, 1, 75, 50)\n",
      "(55872, 1, 75, 50)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train = np.vstack([x_train[:41814], x_train[41817:]])\n",
    "print(x_train.shape, x_train.shape[0] % batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.dump(\"/home/ubuntu/egypt/data/x_train.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55875, 171)\n",
      "(55872, 171) 0\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "y_train = np.vstack([y_train[:41814], y_train[41817:]])\n",
    "print(y_train.shape, y_train.shape[0] % batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.dump(\"/home/ubuntu/egypt/data/y_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
