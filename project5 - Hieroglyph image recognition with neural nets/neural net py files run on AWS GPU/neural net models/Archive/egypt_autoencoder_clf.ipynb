{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import cv2, numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.misc import imread\n",
    "import re\n",
    "import idx2numpy as idx\n",
    "from copy import copy\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# keras\n",
    "np.random.seed(13)\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Reshape, Activation, SimpleRNN, GRU, LSTM, Convolution1D, \\\n",
    "                         MaxPooling1D, Merge, Dropout, Input\n",
    "from IPython.display import SVG\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#from keras.utils.visualize_util import model_to_dot, plot\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Activation, Lambda, Layer # keras.layers.core \n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.datasets import mnist\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import metrics\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootpath = \"../EgyptianHieroglyphDataset/MyTrainTest\"\n",
    "batch_size = 32 // 2 \n",
    "        # TODO 32 is standard; decrease futher for small datasets; \n",
    "        # has to be divisible by num training rows; must be int and not float\n",
    "original_dim = 75 * 50\n",
    "intermediate_dim = 850\n",
    "latent_dim = 10 # had it at 170 but Andrew didn't recommend it\n",
    "epochs = 10 # 50\n",
    "epsilon_std = 1.0\n",
    "n_classes = 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(tr_ts):\n",
    "    \"\"\"\n",
    "    tr_ts: train or test as a string\n",
    "    \"\"\"\n",
    "    if tr_ts == \"train\":\n",
    "        try:\n",
    "            x_train = np.load(\"../data/x_train.pkl\")\n",
    "            y_train = np.load(\"../data/y_train.pkl\")\n",
    "        except:\n",
    "            logging.info(\"Pickle files not found. Creating data from png files.\")\n",
    "            x_train, y_train = get_tr_array_from_png()\n",
    "            x_train.dump(\"../data/x_train.pkl\")\n",
    "            y_train.dump(\"../data/y_train.pkl\")\n",
    "        return x_train, y_train\n",
    "    else:\n",
    "        try:\n",
    "            x_test = np.load(\"../data/x_test.pkl\")\n",
    "            y_test = np.load(\"../data/y_test.pkl\")\n",
    "        except:\n",
    "            logging.info(\"Pickle files not found. Creating data from png files.\")\n",
    "            x_test, y_test = get_ts_array_from_png()\n",
    "            x_test.dump(\"../data/x_test.pkl\")\n",
    "            y_test.dump(\"../data/y_test.pkl\")\n",
    "        return x_test, y_test          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tr_array_from_png():\n",
    "    \"\"\"\n",
    "    data description:\n",
    "        Dataset is compiled by Morris Franken, complementary to the paper titeled \"Automatic Egyptian \\\n",
    "        Hieroglyph Recognition by Retrieving Images as Texts\" (ACM Conference on Multimedia, 2013).\n",
    "    Shape of png file as rgb array:  (75, 50, 3)\n",
    "    future work: too many caveats to fit model to generator for now; need to try and fix it\n",
    "    \"\"\"\n",
    "    n_symbols = symbol_df.shape[0]\n",
    "    batch_arrayfile = np.empty((0, original_dim))\n",
    "    batch_label = np.empty((0, n_symbols))\n",
    "    tr_rootpath = os.path.join(rootpath, \"train\")\n",
    "    subdirs = [x for x in os.listdir(tr_rootpath) if re.search(r\"UNKNOWN|^\\.\", x) == None]\n",
    "    for subdirpath in subdirs:\n",
    "        subdir = os.path.join(tr_rootpath, subdirpath)\n",
    "        files = [x for x in os.listdir(subdir) if re.search(r\"UNKNOWN|^\\.\", x) == None]\n",
    "        for fpath in files:        \n",
    "            pngfile = os.path.join(subdir, fpath)\n",
    "            \n",
    "            # get y\n",
    "            label_txt = re.sub(r\"^.*_(?P<symbol>.*)\\.png$\", \"\\g<symbol>\", pngfile)\n",
    "            cond = symbol_df[\"symbol\"] == label_txt\n",
    "            label_num = int(symbol_df.loc[cond, \"symbol_num\"])\n",
    "            label = np_utils.to_categorical(label_num, n_symbols)\n",
    "            batch_label = np.vstack([batch_label, label])  \n",
    "            \n",
    "            # get x\n",
    "            arrayfile = imread(pngfile, flatten = True, mode = \"RGB\").astype('float32') # flatten means grey scale\n",
    "            arrayfile = np.reshape(arrayfile, original_dim) / 255.\n",
    "            batch_arrayfile = np.vstack([batch_arrayfile, arrayfile])     \n",
    "    return batch_arrayfile, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ts_array_from_png():\n",
    "    \"\"\"\n",
    "    data description:\n",
    "        Dataset is compiled by Morris Franken, complementary to the paper titeled \"Automatic Egyptian \\\n",
    "        Hieroglyph Recognition by Retrieving Images as Texts\" (ACM Conference on Multimedia, 2013).\n",
    "    Shape of png file as rgb array:  (75, 50, 3)\n",
    "    future work: too many caveats to fit model to generator for now; need to try and fix it\n",
    "    \"\"\"\n",
    "    n_symbols = symbol_df.shape[0]\n",
    "    batch_arrayfile = np.empty((0, original_dim))\n",
    "    batch_label = np.empty((0, n_symbols))\n",
    "    ts_rootpath = os.path.join(rootpath, \"test\")\n",
    "    files = [x for x in os.listdir(ts_rootpath) if re.search(r\"UNKNOWN|^\\.\", x) == None]\n",
    "    for fpath in files:\n",
    "        pngfile = os.path.join(ts_rootpath, fpath)\n",
    "            \n",
    "        # get y\n",
    "        label_txt = re.sub(r\"^.*_(?P<symbol>.*)\\.png$\", \"\\g<symbol>\", pngfile)\n",
    "        try:\n",
    "            cond = symbol_df[\"symbol\"] == label_txt\n",
    "            label_num = int(symbol_df.loc[cond, \"symbol_num\"])\n",
    "            label = np_utils.to_categorical(label_num, n_symbols)\n",
    "            batch_label = np.vstack([batch_label, label])\n",
    "            \n",
    "            # get x\n",
    "            arrayfile = imread(pngfile, flatten = True, mode = \"RGB\").astype('float32') # flatten means grey scale\n",
    "            arrayfile = np.reshape(arrayfile, original_dim) / 255.\n",
    "            batch_arrayfile = np.vstack([batch_arrayfile, arrayfile]) \n",
    "        except:\n",
    "            logging.debug(label_txt + \" not found in dictionary. Fix this!\") \n",
    "    return batch_arrayfile, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom loss layer\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded_mean)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol_num</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>Z7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol_num symbol\n",
       "169         169     Z7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_rootpath = os.path.join(rootpath, \"train\")\n",
    "symbol_df = [x for x in os.listdir(tr_rootpath) if re.search(r\"UNKNOWN|^\\.\", x) == None]\n",
    "symbol_df = pd.DataFrame(sorted(symbol_df))\n",
    "symbol_df.reset_index(inplace = True)\n",
    "symbol_df.columns = [\"symbol_num\", \"symbol\"]\n",
    "symbol_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = get_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3584, 3750) (3584, 170)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = get_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 3750) (448, 170)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO convolution, and then encode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(batch_size, original_dim), name = \"input\")\n",
    "h = Dense(intermediate_dim, activation='relu', name = \"encoder1\")(x)\n",
    "z_mean = Dense(latent_dim, name = \"latent\")(h)\n",
    "z_log_var = Dense(latent_dim, name = \"latent_var\")(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name = \"lambda\")([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = CustomVariationalLayer()([x, x_decoded_mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae = Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katharina/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Output \"custom_variational_layer_1\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_1\" during training.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "adm = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "vae.compile(optimizer=adm, loss=None) # rmsprop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3584 samples, validate on 448 samples\n",
      "Epoch 1/10\n",
      "3584/3584 [==============================] - 23s - loss: 2097.3727 - val_loss: 2149.1686\n",
      "Epoch 2/10\n",
      "3584/3584 [==============================] - 22s - loss: 2058.5758 - val_loss: 2168.0678\n",
      "Epoch 3/10\n",
      "3584/3584 [==============================] - 22s - loss: 2046.4633 - val_loss: 2141.6497\n",
      "Epoch 4/10\n",
      "3584/3584 [==============================] - 59s - loss: 2039.5353 - val_loss: 2126.0405\n",
      "Epoch 5/10\n",
      "3584/3584 [==============================] - 53s - loss: 2034.5784 - val_loss: 2125.0604\n",
      "Epoch 6/10\n",
      "3584/3584 [==============================] - 52s - loss: 2031.9612 - val_loss: 2122.1294\n",
      "Epoch 7/10\n",
      "3584/3584 [==============================] - 52s - loss: 2030.1031 - val_loss: 2120.2349\n",
      "Epoch 8/10\n",
      "3584/3584 [==============================] - 52s - loss: 2026.0621 - val_loss: 2112.7509\n",
      "Epoch 9/10\n",
      "3584/3584 [==============================] - 53s - loss: 2023.7579 - val_loss: 2111.3010\n",
      "Epoch 10/10\n",
      "3584/3584 [==============================] - 53s - loss: 2022.8143 - val_loss: 2104.5865\n"
     ]
    }
   ],
   "source": [
    "# train the VAE on MNIST digits\n",
    "history_callback = vae.fit(x_train,\n",
    "                           shuffle=True,\n",
    "                           epochs=epochs,\n",
    "                           batch_size=batch_size,\n",
    "                           validation_data=(x_test, x_test))\n",
    "\n",
    "# vae.fit_generator(tr_generator,\n",
    "#         epochs=epochs,\n",
    "#         steps_per_epoch = 100, \n",
    "#         validation_data=ts_generator, \n",
    "#         validation steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAEKCAYAAADOwb7RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJkmSJEmaYNMkSZIkSRNsmiRJkiRpwk+AZfvsXA7UKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e7a6776a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (14, 4))\n",
    "xaxis = range(epochs)\n",
    "plt.plot(xaxis, history_callback.history['loss'], label = \"train\")\n",
    "plt.plot(xaxis, history_callback.history['val_loss'], label = \"test\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get a separate model (the encoder) that outputs latent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(inputs=x, outputs=z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_wt = encoder.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(encoder_wt[0].shape, encoder_wt[1].shape, encoder_wt[2].shape, encoder_wt[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore encoder result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encoded = encoder.predict(x_train, batch_size=batch_size)\n",
    "tsne = TSNE(n_components = 2)\n",
    "x_train_tsne = tsne.fit_transform(x_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, x_train_encoded.shape, x_train_tsne.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=mpimg.imread(os.path.join(rootpath, \"test\", \"070000_M17.png\"))\n",
    "# plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = pd.Series(np.argmax(y_train, 1), name = \"true\")\n",
    "plt.figure(figsize = (18, 8))\n",
    "plt.title(\"Latent Space T-SNE\")\n",
    "kwargs = {'alpha': 0.7, 's': 40}\n",
    "\n",
    "classes = set(symbol_df[\"symbol_num\"])\n",
    "if classes:\n",
    "    colormap = plt.cm.rainbow(np.linspace(0, 1, len(classes)))\n",
    "    kwargs['c'] = [colormap[i] for i in y_train_cat]\n",
    "    #kwargs['marker'] = r'$\\diamondsuit$' # TODO customize marker shape. Do it in D3?\n",
    "    ax = plt.subplot(111)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    handles = [mpatches.Circle((0, 0), label=class_, color=colormap[i])\n",
    "               for i, class_ in enumerate(classes)]\n",
    "#     ax.legend(handles=handles, shadow=True, bbox_to_anchor=(1.05, 0.45),\n",
    "#               fancybox=True, loc='center left')\n",
    "    \n",
    "plt.scatter(x_train_tsne[:, 0],\n",
    "            x_train_tsne[:, 1],\n",
    "            **kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO pickle encoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build classifier based on latent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del clf\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clf = Sequential()\n",
    "    clf.add(encoder.layers[0])\n",
    "    clf.add(encoder.layers[1])\n",
    "    clf.add(encoder.layers[2])\n",
    "    clf.set_weights(encoder_wt)\n",
    "    \n",
    "    for layer in clf.layers:\n",
    "        layer.trainable = True # False\n",
    "    \n",
    "    clf.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, name='batchnorm1'))\n",
    "    clf.add(Dense(1875, activation='relu', name='clf1'))\n",
    "    clf.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, name='batchnorm2'))\n",
    "    clf.add(Dropout(0.5))\n",
    "    clf.add(Dense(900, activation='relu', name='clf2'))\n",
    "    clf.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, name='batchnorm3'))\n",
    "    clf.add(Dropout(0.7))\n",
    "    clf.add(Dense(n_classes, activation='softmax', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) # TODO slowly lower lr to 0.01 or something else\n",
    "clf.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO  plot number of epochs (x axis) vs. accuracy (y axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = clf.predict(x_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_cat = pd.Series(np.argmax(test_pred, 1), name = \"pred\")\n",
    "y_test_cat = pd.Series(np.argmax(y_test, 1), name = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(test_pred_cat, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for avg in [\"micro\", \"macro\"]:\n",
    "    accuracy = accuracy_score(y_test_cat, test_pred_cat)\n",
    "    precision = precision_score(y_test_cat, test_pred_cat, average = avg)\n",
    "    recall = recall_score(y_test_cat, test_pred_cat, average = avg)\n",
    "    f1 = f1_score(y_test_cat, test_pred_cat, average = avg)\n",
    "    print(avg, \"average: accuracy\", format(accuracy, \"6.4f\"), \\\n",
    "          \"precision\", format(precision, \"6.4f\"), \\\n",
    "          \"recall\", format(recall, \"6.4f\"), \\\n",
    "          \"f1\", format(f1, \"6.4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = pd.Series(np.argmax(y_train, 1), name = \"true\")\n",
    "y_train_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
